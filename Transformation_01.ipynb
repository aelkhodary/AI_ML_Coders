{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPknBMfHjTt4IVPsmCcF/Wi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aelkhodary/AI_ML_Coders/blob/main/Transformation_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs1ljXGNaZgs"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"In this course, you’ll work with LLaVA a Large Vision Language Model (LVLM) that can process both images and text. For example, given an image of a person doing a handstand on a skateboard at the beach, LLaVA doesn't just caption the scene, it’s able to predict possible outcomes, like the person losing balance or falling off. By understanding not just what's in a video frame, but what might happen next\")"
      ],
      "metadata": {
        "id": "j8GxJmh4f18Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text generation**\n",
        "Now let’s see how to use a pipeline to generate some text. The main idea here is that you provide a prompt and the model will auto-complete it by generating the remaining text. This is similar to the predictive text feature that is found on many phones. Text generation involves randomness, so it’s normal if you don’t get the same results as shown below."
      ],
      "metadata": {
        "id": "XrjOcABar34P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"هلا مرحبا\")"
      ],
      "metadata": {
        "id": "rpj3pvFHr8pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P2xgxxocuRki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy==2.0\n",
        "!pip install fsspec==2024.6.1"
      ],
      "metadata": {
        "id": "3mu7w9BGvbpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==2.14.5\n"
      ],
      "metadata": {
        "id": "6QipnDTsu5ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "E0WqIy020SF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, ViTForImageClassification\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset = load_dataset(\"huggingface/cats-image\", trust_remote_code=True)\n",
        "# Get the first image from the 'test' set\n",
        "image = dataset[\"test\"][\"image\"][0]\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Remove axes\n",
        "plt.show()\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "\n",
        "inputs = image_processor(image, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "# model predicts one of the 1000 ImageNet classes\n",
        "predicted_label = logits.argmax(-1).item()\n",
        "print(model.config.id2label[predicted_label])"
      ],
      "metadata": {
        "id": "48aslxYKuSOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mask filling**\n",
        "The next pipeline you’ll try is fill-mask. The idea of this task is to fill in the blanks in a given text:"
      ],
      "metadata": {
        "id": "WCAJEQ-Q77lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all aboutt  <mask> models.\", top_k=2)"
      ],
      "metadata": {
        "id": "9iJP5KlR8DPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named entity recognition**\n",
        "Named entity recognition (NER) is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations. Let’s look at an example:"
      ],
      "metadata": {
        "id": "oTX4eji--len"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Ahmed and I work at SCAD in Abu Dhabi.\")"
      ],
      "metadata": {
        "id": "XhwziRng-p3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question answering**\n",
        "The question-answering pipeline answers questions using information from a given context:"
      ],
      "metadata": {
        "id": "7HeBR-GLVnuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work and what is my name?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ],
      "metadata": {
        "id": "0AiAmwF6Vrrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summarization**\n",
        "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text. Here’s an example:"
      ],
      "metadata": {
        "id": "BHYE2ErKY1bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Ahmed Elkhodary start test the model,He has 36 years old ,\n",
        "    working as architect engineer.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "EHNm40ViY5YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DuRvOqt_cSbm"
      }
    }
  ]
}