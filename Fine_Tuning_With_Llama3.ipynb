{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNKSZYdO6plOYa0/daVUJPA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b09527ccd4734a1bad247e9f598895de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fee6c53ef6e47168fce1c2fdba23f33",
              "IPY_MODEL_ea467f7fc7bd48de925acd5d37577e80",
              "IPY_MODEL_818362a4aa714f76adb6a6a95f369f9b"
            ],
            "layout": "IPY_MODEL_6bf17cfd686c4acd810fff38aebd4462"
          }
        },
        "5fee6c53ef6e47168fce1c2fdba23f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7efd154a1d184bcfbb0805a6ad779066",
            "placeholder": "​",
            "style": "IPY_MODEL_dc241689c06346fcb4f43f834b27a703",
            "value": "README.md: 100%"
          }
        },
        "ea467f7fc7bd48de925acd5d37577e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc1cac0792b487d9a12a0f9f71701d6",
            "max": 233,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9083d59a8b914b85bb9342ec883a3667",
            "value": 233
          }
        },
        "818362a4aa714f76adb6a6a95f369f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_974e0f7fdc524d7e884fb42e39b6e4d1",
            "placeholder": "​",
            "style": "IPY_MODEL_678d5b7a84ba4d20afb1c1196a942095",
            "value": " 233/233 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "6bf17cfd686c4acd810fff38aebd4462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efd154a1d184bcfbb0805a6ad779066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc241689c06346fcb4f43f834b27a703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efc1cac0792b487d9a12a0f9f71701d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9083d59a8b914b85bb9342ec883a3667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "974e0f7fdc524d7e884fb42e39b6e4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "678d5b7a84ba4d20afb1c1196a942095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba8a0f8be49412ba4e8a05ad6f02cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15743f09ee2c488e85aeded7f93324a7",
              "IPY_MODEL_67ecb29fc68848119a416f8ba1ded5ea",
              "IPY_MODEL_557a9440f4a94e339071986d2d2b986f"
            ],
            "layout": "IPY_MODEL_7613fcf652914d618a41f4f6c00448da"
          }
        },
        "15743f09ee2c488e85aeded7f93324a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b09c45dcba347d895621f1657b6a81c",
            "placeholder": "​",
            "style": "IPY_MODEL_9daf01f380254aca9aedb3c08858a672",
            "value": "medDataset_processed.csv: 100%"
          }
        },
        "67ecb29fc68848119a416f8ba1ded5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8816fef09cb147ea959e8d0aecddc7b1",
            "max": 22466890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d21fb8feb924ebf9d150fe9b61429fd",
            "value": 22466890
          }
        },
        "557a9440f4a94e339071986d2d2b986f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02f98c543d84bfcbf01406f0d4fb7ba",
            "placeholder": "​",
            "style": "IPY_MODEL_3c895235dc07482aa34a02bfaaeb71d8",
            "value": " 22.5M/22.5M [00:00&lt;00:00, 51.5MB/s]"
          }
        },
        "7613fcf652914d618a41f4f6c00448da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b09c45dcba347d895621f1657b6a81c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9daf01f380254aca9aedb3c08858a672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8816fef09cb147ea959e8d0aecddc7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d21fb8feb924ebf9d150fe9b61429fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c02f98c543d84bfcbf01406f0d4fb7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c895235dc07482aa34a02bfaaeb71d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "861fb65dc23241f7864d403dfb0c52cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98a2a846dea44c1fb60e591599595252",
              "IPY_MODEL_b33fba8e64124bdea3b12fc872db1c0f",
              "IPY_MODEL_970483609c42402dbf69d901df522d05"
            ],
            "layout": "IPY_MODEL_3bf6983af9264d17970209b062edda8c"
          }
        },
        "98a2a846dea44c1fb60e591599595252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39aa14b51ed24a338f1def004c2bb97e",
            "placeholder": "​",
            "style": "IPY_MODEL_978924a7603e496b950477bdcc9615ea",
            "value": "Generating train split: 100%"
          }
        },
        "b33fba8e64124bdea3b12fc872db1c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5e4de213bb74f86ac5bf2e4dc1dd518",
            "max": 16407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43448fdbada74eb58b2bf16f952a3687",
            "value": 16407
          }
        },
        "970483609c42402dbf69d901df522d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88432e0822824e759993ca0c3373f2c3",
            "placeholder": "​",
            "style": "IPY_MODEL_bf7b893b55aa48658c9ff12fb8bfca81",
            "value": " 16407/16407 [00:00&lt;00:00, 56696.46 examples/s]"
          }
        },
        "3bf6983af9264d17970209b062edda8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39aa14b51ed24a338f1def004c2bb97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978924a7603e496b950477bdcc9615ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5e4de213bb74f86ac5bf2e4dc1dd518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43448fdbada74eb58b2bf16f952a3687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88432e0822824e759993ca0c3373f2c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7b893b55aa48658c9ff12fb8bfca81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0a810f00078445eac259e48eaacb0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db2a07337a7846d19531d0233b689857",
              "IPY_MODEL_768ed1effaeb49d38fcbe31204d3ba6f",
              "IPY_MODEL_171a36379e014882b4aea0061c89e387"
            ],
            "layout": "IPY_MODEL_65db58e0194e40af9f217d62aa7630c6"
          }
        },
        "db2a07337a7846d19531d0233b689857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b86f9209e9b34e848b020f6a5de6eeb4",
            "placeholder": "​",
            "style": "IPY_MODEL_2207b00119bf4e8daa25735b33d5e100",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "768ed1effaeb49d38fcbe31204d3ba6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1639ced113cd42ccbac0c11444f31a5e",
            "max": 26872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a00569937d344bfa454104aaac03772",
            "value": 26872
          }
        },
        "171a36379e014882b4aea0061c89e387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb8219be13c40c39445561dd39718a4",
            "placeholder": "​",
            "style": "IPY_MODEL_9c9864be9e124d7292202bbd8d978994",
            "value": " 26872/26872 [00:00&lt;00:00, 248572.18 examples/s]"
          }
        },
        "65db58e0194e40af9f217d62aa7630c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86f9209e9b34e848b020f6a5de6eeb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2207b00119bf4e8daa25735b33d5e100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1639ced113cd42ccbac0c11444f31a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a00569937d344bfa454104aaac03772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cb8219be13c40c39445561dd39718a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9864be9e124d7292202bbd8d978994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aelkhodary/AI_ML_Coders/blob/main/Fine_Tuning_With_Llama3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "-ZZrxdW-G43g"
      },
      "outputs": [],
      "source": [
        "!pip install torchao -q\n",
        "!pip3 install torchtune -q\n",
        "# Install the datasets library\n",
        "!pip install datasets -q\n",
        "# Install the huggingface_hub library\n",
        "!pip install huggingface_hub -q\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/bin'"
      ],
      "metadata": {
        "id": "H7f5iQKSJ5GQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which tune\n",
        "!tune ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCYr0t0EJSpB",
        "outputId": "62bb4ca1-f6f8-482d-b746-8afe3235621f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/tune\n",
            "RECIPE                                   CONFIG                                  \n",
            "full_finetune_single_device              llama2/7B_full_low_memory               \n",
            "                                         code_llama2/7B_full_low_memory          \n",
            "                                         llama3/8B_full_single_device            \n",
            "                                         llama3_1/8B_full_single_device          \n",
            "                                         llama3_2/1B_full_single_device          \n",
            "                                         llama3_2/3B_full_single_device          \n",
            "                                         mistral/7B_full_low_memory              \n",
            "                                         phi3/mini_full_low_memory               \n",
            "                                         qwen2/7B_full_single_device             \n",
            "                                         qwen2/0.5B_full_single_device           \n",
            "                                         qwen2/1.5B_full_single_device           \n",
            "                                         qwen2_5/0.5B_full_single_device         \n",
            "                                         qwen2_5/1.5B_full_single_device         \n",
            "                                         qwen2_5/3B_full_single_device           \n",
            "                                         qwen2_5/7B_full_single_device           \n",
            "                                         llama3_2_vision/11B_full_single_device  \n",
            "full_finetune_distributed                llama2/7B_full                          \n",
            "                                         llama2/13B_full                         \n",
            "                                         llama3/8B_full                          \n",
            "                                         llama3_1/8B_full                        \n",
            "                                         llama3_2/1B_full                        \n",
            "                                         llama3_2/3B_full                        \n",
            "                                         llama3/70B_full                         \n",
            "                                         llama3_1/70B_full                       \n",
            "                                         llama3_3/70B_full                       \n",
            "                                         mistral/7B_full                         \n",
            "                                         gemma/2B_full                           \n",
            "                                         gemma/7B_full                           \n",
            "                                         gemma2/2B_full                          \n",
            "                                         gemma2/9B_full                          \n",
            "                                         gemma2/27B_full                         \n",
            "                                         phi3/mini_full                          \n",
            "                                         qwen2/7B_full                           \n",
            "                                         qwen2/0.5B_full                         \n",
            "                                         qwen2/1.5B_full                         \n",
            "                                         qwen2_5/0.5B_full                       \n",
            "                                         qwen2_5/1.5B_full                       \n",
            "                                         qwen2_5/3B_full                         \n",
            "                                         qwen2_5/7B_full                         \n",
            "                                         llama3_2_vision/11B_full                \n",
            "                                         llama3_2_vision/90B_full                \n",
            "lora_finetune_single_device              llama2/7B_lora_single_device            \n",
            "                                         llama2/7B_qlora_single_device           \n",
            "                                         code_llama2/7B_lora_single_device       \n",
            "                                         code_llama2/7B_qlora_single_device      \n",
            "                                         llama3/8B_lora_single_device            \n",
            "                                         llama3_1/8B_lora_single_device          \n",
            "                                         llama3/8B_qlora_single_device           \n",
            "                                         llama3_2/1B_lora_single_device          \n",
            "                                         llama3_2/3B_lora_single_device          \n",
            "                                         llama3/8B_dora_single_device            \n",
            "                                         llama3/8B_qdora_single_device           \n",
            "                                         llama3_1/8B_qlora_single_device         \n",
            "                                         llama3_2/1B_qlora_single_device         \n",
            "                                         llama3_2/3B_qlora_single_device         \n",
            "                                         llama2/13B_qlora_single_device          \n",
            "                                         mistral/7B_lora_single_device           \n",
            "                                         mistral/7B_qlora_single_device          \n",
            "                                         gemma/2B_lora_single_device             \n",
            "                                         gemma/2B_qlora_single_device            \n",
            "                                         gemma/7B_lora_single_device             \n",
            "                                         gemma/7B_qlora_single_device            \n",
            "                                         gemma2/2B_lora_single_device            \n",
            "                                         gemma2/2B_qlora_single_device           \n",
            "                                         gemma2/9B_lora_single_device            \n",
            "                                         gemma2/9B_qlora_single_device           \n",
            "                                         gemma2/27B_lora_single_device           \n",
            "                                         gemma2/27B_qlora_single_device          \n",
            "                                         phi3/mini_lora_single_device            \n",
            "                                         phi3/mini_qlora_single_device           \n",
            "                                         qwen2/7B_lora_single_device             \n",
            "                                         qwen2/0.5B_lora_single_device           \n",
            "                                         qwen2/1.5B_lora_single_device           \n",
            "                                         qwen2_5/0.5B_lora_single_device         \n",
            "                                         qwen2_5/1.5B_lora_single_device         \n",
            "                                         qwen2_5/3B_lora_single_device           \n",
            "                                         qwen2_5/7B_lora_single_device           \n",
            "                                         qwen2_5/14B_lora_single_device          \n",
            "                                         llama3_2_vision/11B_lora_single_device  \n",
            "                                         llama3_2_vision/11B_qlora_single_device \n",
            "lora_dpo_single_device                   llama2/7B_lora_dpo_single_device        \n",
            "                                         llama3_1/8B_lora_dpo_single_device      \n",
            "lora_dpo_distributed                     llama2/7B_lora_dpo                      \n",
            "                                         llama3_1/8B_lora_dpo                    \n",
            "ppo_full_finetune_single_device          mistral/7B_full_ppo_low_memory          \n",
            "lora_finetune_distributed                llama2/7B_lora                          \n",
            "                                         llama2/13B_lora                         \n",
            "                                         llama2/70B_lora                         \n",
            "                                         llama2/7B_qlora                         \n",
            "                                         llama2/70B_qlora                        \n",
            "                                         llama3/8B_dora                          \n",
            "                                         llama3/70B_lora                         \n",
            "                                         llama3_1/70B_lora                       \n",
            "                                         llama3_3/70B_lora                       \n",
            "                                         llama3_3/70B_qlora                      \n",
            "                                         llama3/8B_lora                          \n",
            "                                         llama3_1/8B_lora                        \n",
            "                                         llama3_2/1B_lora                        \n",
            "                                         llama3_2/3B_lora                        \n",
            "                                         llama3_1/405B_qlora                     \n",
            "                                         mistral/7B_lora                         \n",
            "                                         gemma/2B_lora                           \n",
            "                                         gemma/7B_lora                           \n",
            "                                         gemma2/2B_lora                          \n",
            "                                         gemma2/9B_lora                          \n",
            "                                         gemma2/27B_lora                         \n",
            "                                         phi3/mini_lora                          \n",
            "                                         qwen2/7B_lora                           \n",
            "                                         qwen2/0.5B_lora                         \n",
            "                                         qwen2/1.5B_lora                         \n",
            "                                         qwen2_5/0.5B_lora                       \n",
            "                                         qwen2_5/1.5B_lora                       \n",
            "                                         qwen2_5/3B_lora                         \n",
            "                                         qwen2_5/7B_lora                         \n",
            "                                         qwen2_5/32B_lora                        \n",
            "                                         qwen2_5/72B_lora                        \n",
            "                                         llama3_2_vision/11B_lora                \n",
            "                                         llama3_2_vision/11B_qlora               \n",
            "                                         llama3_2_vision/90B_lora                \n",
            "                                         llama3_2_vision/90B_qlora               \n",
            "generate                                 generation                              \n",
            "dev/generate_v2                          llama2/generation_v2                    \n",
            "                                         llama3_2_vision/11B_generation_v2       \n",
            "dev/early_exit_finetune_distributed      llama2/7B_full_early_exit               \n",
            "eleuther_eval                            eleuther_evaluation                     \n",
            "                                         llama3_2_vision/11B_evaluation          \n",
            "                                         qwen2/evaluation                        \n",
            "                                         gemma/evaluation                        \n",
            "                                         phi3/evaluation                         \n",
            "                                         mistral/evaluation                      \n",
            "quantize                                 quantization                            \n",
            "qat_distributed                          llama2/7B_qat_full                      \n",
            "                                         llama3/8B_qat_full                      \n",
            "qat_lora_finetune_distributed            llama3/8B_qat_lora                      \n",
            "                                         llama3_1/8B_qat_lora                    \n",
            "                                         llama3_2/1B_qat_lora                    \n",
            "                                         llama3_2/3B_qat_lora                    \n",
            "knowledge_distillation_single_device     qwen2/1.5_to_0.5B_KD_lora_single_device \n",
            "                                         llama3_2/8B_to_1B_KD_lora_single_device \n",
            "knowledge_distillation_distributed       qwen2/1.5_to_0.5B_KD_lora_distributed   \n",
            "                                         llama3_2/8B_to_1B_KD_lora_distributed   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**:\n",
        "\n",
        "Listing TorchTune recipes\n",
        "You are working on a text classification project to fine-tune a 1 billion parameter Llama 3.2 model. Given your hardware constraints, you need to choose a single device configuration, with full fine-tuning. To list all available options, you can use the console and run !tune ls.\n",
        "\n",
        "Which recipe would be compatible with your model based on the constraints?\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "Possible answers\n",
        "\n",
        "\n",
        "\n",
        "full_finetune_distributed with the llama3_2/1B_full configuration\n",
        "\n",
        "full_finetune_single_device with the llama3_1/8B_full_single_device configuration\n",
        "\n",
        ">>> full_finetune_single_device with the llama3_2/1B_full_single_device configuration"
      ],
      "metadata": {
        "id": "g0LkUDqWNcgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running a TorchTune task**:\n",
        "\n",
        "Having listed your choices with !tune ls, you are now ready to launch your fine-tuning task with the recipe and configuration for your Llama 3.2, 1B model on single device (full_finetune_single_device with llama3_2/1B_full_single_device).\n",
        "\n",
        "Which of the following commands will you use to run the task for 20 epochs, on a single device GPU?\n",
        "\n",
        "\n",
        "**Possible Answers**\n",
        "\n",
        "\n",
        "!torchtune run full_finetune_single_device --config llama3_2/1B_full_single_device device=cpu epochs=0\n",
        "\n",
        "\n",
        ">> !tune run full_finetune_single_device --config llama3_2/1B_full_single_device device=cuda epochs=20\n",
        "\n",
        "\n",
        "!tune run full_finetune_single_device --config llama3_2/1B_full_single_device device=gpu epochs=20"
      ],
      "metadata": {
        "id": "0DT5CuCeO5i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**:\n",
        "\n",
        "Filtering datasets for evaluation\n",
        "You are building a training and evaluation pipeline for your company's health care chatbot, which is used by hospitals to onboard new patients.\n",
        "\n",
        "Your task is to create a pipeline to load the MedQuad-MedicalQnADataset to evaluate an LLM on its ability to answer medical questions. You are asked to load the dataset in the ds variable, and only include the first 500 samples of the train split of the dataset stored in dataset_name as your evaluation set.\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "Import necessary functions and classes from datasets.\n",
        "Load the dataset in the ds variable.\n",
        "Manipulate ds to include the first 500 samples of the train split of the dataset stored in dataset_name as your evaluation set."
      ],
      "metadata": {
        "id": "Yxr4LojfjFt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load neccesary imports from library\n",
        "from datasets import load_dataset, Dataset\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from pprint import pprint\n",
        "\n",
        "# Retrieve the Hugging Face API key from Colab Secrets\n",
        "hf_api_key = userdata.get('HF_TOKEN')\n",
        "# Log in to Hugging Face\n",
        "login(token=hf_api_key)\n",
        "\n",
        "dataset_name = \"keivalya/MedQuad-MedicalQnADataset\"\n",
        "# Load the training split of the dataset\n",
        "ds = load_dataset(dataset_name, split='train')\n",
        "\n",
        "# Filter for the first 500 samples of the dataset\n",
        "filtered_ds = Dataset.from_dict(ds[:500])\n",
        "print(filtered_ds.shape)\n",
        "print(filtered_ds.column_names)\n",
        "pprint(filtered_ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "b09527ccd4734a1bad247e9f598895de",
            "5fee6c53ef6e47168fce1c2fdba23f33",
            "ea467f7fc7bd48de925acd5d37577e80",
            "818362a4aa714f76adb6a6a95f369f9b",
            "6bf17cfd686c4acd810fff38aebd4462",
            "7efd154a1d184bcfbb0805a6ad779066",
            "dc241689c06346fcb4f43f834b27a703",
            "efc1cac0792b487d9a12a0f9f71701d6",
            "9083d59a8b914b85bb9342ec883a3667",
            "974e0f7fdc524d7e884fb42e39b6e4d1",
            "678d5b7a84ba4d20afb1c1196a942095",
            "aba8a0f8be49412ba4e8a05ad6f02cbb",
            "15743f09ee2c488e85aeded7f93324a7",
            "67ecb29fc68848119a416f8ba1ded5ea",
            "557a9440f4a94e339071986d2d2b986f",
            "7613fcf652914d618a41f4f6c00448da",
            "0b09c45dcba347d895621f1657b6a81c",
            "9daf01f380254aca9aedb3c08858a672",
            "8816fef09cb147ea959e8d0aecddc7b1",
            "9d21fb8feb924ebf9d150fe9b61429fd",
            "c02f98c543d84bfcbf01406f0d4fb7ba",
            "3c895235dc07482aa34a02bfaaeb71d8",
            "861fb65dc23241f7864d403dfb0c52cb",
            "98a2a846dea44c1fb60e591599595252",
            "b33fba8e64124bdea3b12fc872db1c0f",
            "970483609c42402dbf69d901df522d05",
            "3bf6983af9264d17970209b062edda8c",
            "39aa14b51ed24a338f1def004c2bb97e",
            "978924a7603e496b950477bdcc9615ea",
            "f5e4de213bb74f86ac5bf2e4dc1dd518",
            "43448fdbada74eb58b2bf16f952a3687",
            "88432e0822824e759993ca0c3373f2c3",
            "bf7b893b55aa48658c9ff12fb8bfca81"
          ]
        },
        "id": "Md8wauy0Ns4S",
        "outputId": "4434f0c5-1552-40e1-b9b6-22fdee24b8da"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/233 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b09527ccd4734a1bad247e9f598895de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "medDataset_processed.csv:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aba8a0f8be49412ba4e8a05ad6f02cbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/16407 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "861fb65dc23241f7864d403dfb0c52cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3)\n",
            "['qtype', 'Question', 'Answer']\n",
            "{'Answer': 'LCMV infections can occur after exposure to fresh urine, '\n",
            "           'droppings, saliva, or nesting materials from infected rodents.  '\n",
            "           'Transmission may also occur when these materials are directly '\n",
            "           'introduced into broken skin, the nose, the eyes, or the mouth, or '\n",
            "           'presumably, via the bite of an infected rodent. Person-to-person '\n",
            "           'transmission has not been reported, with the exception of vertical '\n",
            "           'transmission from infected mother to fetus, and rarely, through '\n",
            "           'organ transplantation.',\n",
            " 'Question': 'Who is at risk for Lymphocytic Choriomeningitis (LCM)? ?',\n",
            " 'qtype': 'susceptibility'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**:\n",
        "\n",
        "Creating training samples\n",
        "As part of a customer service chatbot that your team is building, you are creating a pipeline to preprocess a dataset that will eventually be used to fine-tune a language model so that it can predict the intent of a customer's question and route the requests to the correct team for processing.\n",
        "\n",
        "You are given a dataset with the customer's question and intent in separate columns, and you want to preprocess the dataset so that you have merged each example containing the question and intent into a single string with your formatted prompt.\n",
        "\n",
        "The dataset is already loaded in dataset. The dataset contains the columns instruction with the customer question, and intent for the user's intent.\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "Create a prompt string with the instruction and intent in the form \"Query: {instruction}\\nIntent: {intent}\".\n",
        "Fill out the function call with the dataset to apply the create_intent_example to each row.\n",
        "Extract and print out the value in the intent_example column in the first row of the dataset."
      ],
      "metadata": {
        "id": "RnTWvHgGKGkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load neccesary imports from library\n",
        "from datasets import load_dataset, Dataset\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from pprint import pprint\n",
        "\n",
        "# Retrieve the Hugging Face API key from Colab Secrets\n",
        "hf_api_key = userdata.get('HF_TOKEN')\n",
        "# Log in to Hugging Face\n",
        "login(token=hf_api_key)\n",
        "\n",
        "dataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\"\n",
        "# Load the training split of the dataset\n",
        "ds = load_dataset(dataset_name, split='train')\n",
        "\n",
        "print(ds.shape)\n",
        "print(ds.column_names)\n",
        "pprint(ds[0])\n",
        "\n",
        "def create_intent_example(row):\n",
        "    # Fill out the columns in the prompt\n",
        "    row['intent_example'] = f\"Query: {row['instruction']}\\nIntent: {row['intent']}\"\n",
        "    return row\n",
        "\n",
        "def create_conversation_example(row):\n",
        "    # Fill out the columns in the prompt\n",
        "    row['conversation_example'] = f\"Query: {row['instruction']}\\nResponse: {row['response']}\"\n",
        "    return row\n",
        "\n",
        "# Call the ds method to apply our preprocessing function to all rows\n",
        "processed_dataset = ds.map(create_intent_example)\n",
        "processed_dataset = processed_dataset.map(create_conversation_example)\n",
        "\n",
        "# Print the intent_example in the first row of the processed data\n",
        "print(processed_dataset[0]['intent_example'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RugfiZT2KHOD",
        "outputId": "a4013b83-7fe4-4d28-a203-e37a62bda49f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26872, 5)\n",
            "['flags', 'instruction', 'category', 'intent', 'response']\n",
            "{'category': 'ORDER',\n",
            " 'flags': 'B',\n",
            " 'instruction': 'question about cancelling order {{Order Number}}',\n",
            " 'intent': 'cancel_order',\n",
            " 'response': \"I've understood you have a question regarding canceling order \"\n",
            "             \"{{Order Number}}, and I'm here to provide you with the \"\n",
            "             'information you need. Please go ahead and ask your question, and '\n",
            "             \"I'll do my best to assist you.\"}\n",
            "Query: question about cancelling order {{Order Number}}\n",
            "Intent: cancel_order\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**:\n",
        "\n",
        "Saving preprocessed datasets\n",
        "As part of your customer service chatbot project, you now have prepared a dataset for fine-tuning a Llama model. The next step is to save the dataset so that you can reload it later without having to repeat the preprocessing steps. This will allow your team to reuse the dataset across multiple experiments and iterations.\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "\n",
        "Save the preprocessed dataset ds to disk.\n",
        "Load the saved dataset into a new variable ds_preprocessed.\n",
        "Print the first element of ds_preprocessed."
      ],
      "metadata": {
        "id": "2sSf_Z2KMo3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "from pprint import pprint\n",
        "\n",
        "# Save the dataset to disk\n",
        "processed_dataset.save_to_disk(\"/content/processed_dataset\")\n",
        "\n",
        "# Load the dataset from disk\n",
        "ds_preprocessed = load_from_disk(\"/content/processed_dataset\")\n",
        "\n",
        "# Print the first element of the loaded dataset\n",
        "print(ds_preprocessed.shape)\n",
        "print(ds_preprocessed.column_names)\n",
        "pprint(ds_preprocessed[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "d0a810f00078445eac259e48eaacb0bb",
            "db2a07337a7846d19531d0233b689857",
            "768ed1effaeb49d38fcbe31204d3ba6f",
            "171a36379e014882b4aea0061c89e387",
            "65db58e0194e40af9f217d62aa7630c6",
            "b86f9209e9b34e848b020f6a5de6eeb4",
            "2207b00119bf4e8daa25735b33d5e100",
            "1639ced113cd42ccbac0c11444f31a5e",
            "5a00569937d344bfa454104aaac03772",
            "6cb8219be13c40c39445561dd39718a4",
            "9c9864be9e124d7292202bbd8d978994"
          ]
        },
        "id": "KREjayjkMwC4",
        "outputId": "083246aa-b774-484b-f5fc-bfa8ad7d974d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/26872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0a810f00078445eac259e48eaacb0bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26872, 7)\n",
            "['flags', 'instruction', 'category', 'intent', 'response', 'intent_example', 'conversation_example']\n",
            "{'category': 'ORDER',\n",
            " 'conversation_example': 'Query: question about cancelling order {{Order '\n",
            "                         'Number}}\\n'\n",
            "                         \"Response: I've understood you have a question \"\n",
            "                         \"regarding canceling order {{Order Number}}, and I'm \"\n",
            "                         'here to provide you with the information you need. '\n",
            "                         \"Please go ahead and ask your question, and I'll do \"\n",
            "                         'my best to assist you.',\n",
            " 'flags': 'B',\n",
            " 'instruction': 'question about cancelling order {{Order Number}}',\n",
            " 'intent': 'cancel_order',\n",
            " 'intent_example': 'Query: question about cancelling order {{Order Number}}\\n'\n",
            "                   'Intent: cancel_order',\n",
            " 'response': \"I've understood you have a question regarding canceling order \"\n",
            "             \"{{Order Number}}, and I'm here to provide you with the \"\n",
            "             'information you need. Please go ahead and ask your question, and '\n",
            "             \"I'll do my best to assist you.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**:\n",
        "\n",
        "Defining custom recipes\n",
        "You're fine-tuning a pre-trained Llama model for a customer who requires specific configurations. Your plan is to use TorchTune for fine-tuning, and so need to prepare a Python dictionary that you can use to store the requirements for the custom recipe you'll use to run the fine-tuning job.\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "Specify the customer requirements in your dictionary: first, add the torchtune.models.llama3_2.llama3_2_1b model.\n",
        "Add a batch size of 8 and a GPU device.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Specify the new model requirement, the \"torchtune.models.llama3_2.llama3_2_3b\" model, in your dictionary.\n",
        "Save the requirements as a YAML file named custom_recipe.yaml."
      ],
      "metadata": {
        "id": "ivn2zXnQkVGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchtune\n",
        "!pip show torchtune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knQX9xn69M2B",
        "outputId": "1f90b345-8b20-4d5e-e06f-e6957f6fae2e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtune in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from torchtune) (3.3.2)\n",
            "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.5.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.3.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.9.0)\n",
            "Requirement already satisfied: blobfile>=2 in /usr/local/lib/python3.11/dist-packages (from torchtune) (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtune) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtune) (4.67.1)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from torchtune) (2.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from torchtune) (5.9.5)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from torchtune) (11.1.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.21.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (2.3.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (5.3.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->torchtune) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.11.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (4.12.2)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (0.1.9)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->torchtune) (4.9.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->torchtune) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.17.0)\n",
            "Name: torchtune\n",
            "Version: 0.5.0\n",
            "Summary: A native-PyTorch library for LLM fine-tuning\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: PyTorch Team <packages@pytorch.org>\n",
            "License: BSD 3-Clause License\n",
            "\n",
            "Copyright 2024 Meta\n",
            "\n",
            "Redistribution and use in source and binary forms, with or without modification,\n",
            "are permitted provided that the following conditions are met:\n",
            "\n",
            "1. Redistributions of source code must retain the above copyright notice,this list\n",
            "of conditions and the following disclaimer.\n",
            "\n",
            "2. Redistributions in binary form must reproduce the above copyright notice, this\n",
            "list of conditions and the following disclaimer in the documentation\n",
            "and/or other materials provided with the distribution.\n",
            "\n",
            "3. Neither the name of the copyright holder nor the names of its contributors may\n",
            "be used to endorse or promote products derived from this software without specific\n",
            "prior written permission.\n",
            "\n",
            "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY\n",
            "EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n",
            "OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT\n",
            "SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n",
            "INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n",
            "TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR\n",
            "BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
            "CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n",
            "ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n",
            "DAMAGE.\n",
            "\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: blobfile, datasets, huggingface_hub, kagglehub, numpy, omegaconf, Pillow, psutil, safetensors, sentencepiece, tiktoken, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# config_dict = {\n",
        "#     # Define the model\n",
        "#     \"model\": {\"_component_\": \"torchtune.models.llama3_2.llama3_2_3b\"},\n",
        "\n",
        "#     # Define the batch size\n",
        "#     \"batch_size\": 8,\n",
        "\n",
        "#     # Define the device type\n",
        "#     \"device\": \"cuda\",\n",
        "\n",
        "#     # Define the number of epochs\n",
        "#     \"epochs\": 1,\n",
        "\n",
        "#     # Define the optimizer\n",
        "#     \"optimizer\": {\"_component_\": \"bitsandbytes.optim.PagedAdamW8bit\", \"lr\": 3e-05},\n",
        "\n",
        "#     # Define the dataset\n",
        "#     \"dataset\": {\"_component_\": \"processed_dataset\"},\n",
        "\n",
        "#     # Define the output directory\n",
        "#     \"output_dir\": \"finetune_results\",\n",
        "\n",
        "#     # Define dtype\n",
        "#     \"dtype\": \"bf16\",\n",
        "#     # Define path to an actual checkpoint\n",
        "#     \"resume_from_checkpoint\": \"\",\n",
        "\n",
        "#     \"gradient_accumulation_steps\": 1\n",
        "# }\n",
        "\n",
        "\n",
        "config_dict = {\n",
        "  \"device\": \"cuda\",\n",
        "  \"dtype\": \"bf16\",\n",
        "  \"epochs\": 1,\n",
        "  \"batch_size\": 8,\n",
        "  \"shuffle\": \"true\",\n",
        "  \"resume_from_checkpoint\": \"\",\n",
        "  \"gradient_accumulation_steps\": 1,\n",
        "  \"optimizer_in_bwd\": \"false\",\n",
        "  \"seed\": 42,\n",
        "  \"checkpointer\": {\n",
        "    \"_component_\": \"torchtune.training.Checkpointer\",\n",
        "    \"model_type\": \"default\",\n",
        "    \"output_dir\": \"finetune_results\",\n",
        "    \"frequency\": \"epoch\",\n",
        "    \"keep_last\": \"true\"\n",
        "  },\n",
        "  \"metric_logger\":{\n",
        "             \"_component_\": \"torchtune.logging.ConsoleLogger\"\n",
        "\n",
        "  },\n",
        "  \"log_every_n_steps\": 10,\n",
        "  \"log_peak_memory_stats\": \"false\",\n",
        "  \"model\": {\n",
        "    \"_component_\": \"torchtune.models.llama3_2.llama3_2_3b\"\n",
        "  },\n",
        "  \"optimizer\": {\n",
        "    \"_component_\": \"bitsandbytes.optim.PagedAdamW8bit\",\n",
        "    \"lr\": 3.0e-05\n",
        "  },\n",
        "  \"tokenizer\": {\n",
        "    \"_component_\": \"torchtune.text_tokenizers.llama_tokenizer\",\n",
        "    \"pretrained_tokenizer\": \"/path/to/tokenizer\",\n",
        "    \"special_tokens\": []\n",
        "  },\n",
        "  \"loss\": {\n",
        "    \"_component_\": \"torchtune.modules.cross_entropy_loss\",\n",
        "    \"ignore_index\": -100,\n",
        "    \"reduction\": \"mean\"\n",
        "  },\n",
        "  \"dataset\": {\n",
        "    \"_component_\": \"processed_dataset\"\n",
        "  },\n",
        "  \"output_dir\": \"finetune_results\",\n",
        "  \"enable_activation_checkpointing\": \"false\",\n",
        "  \"enable_activation_offloading\": \"false\",\n",
        "  \"compile\": \"false\",\n",
        "  \"max_steps_per_epoch\": \"null\"\n",
        "}\n",
        "\n",
        "# Save the updated configuration to a new YAML file\n",
        "with open(\"/content/custom_recipe.yaml\", \"w\") as yaml_file:\n",
        "    yaml.dump(config_dict, yaml_file)\n"
      ],
      "metadata": {
        "id": "HBxHXgWCkdB9"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running custom fine-tuning**\n",
        "\n",
        "tune run --config custom_recipe.yaml"
      ],
      "metadata": {
        "id": "AuG1TtvFqF4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!cat custom_recipe.yaml\n",
        "# !tune run --help\n",
        "# usage: tune run [TORCHRUN-OPTIONS] <recipe> --config <config> [RECIPE-OPTIONS]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fe8m7fLqVUO",
        "outputId": "d36cee5b-a756-40bd-fb8c-7c0cc7692c85"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3B_full_single_device.py  full_finetune_single_device.py  sample_data\n",
            "custom_recipe.yaml\t  processed_dataset\n",
            "batch_size: 8\n",
            "checkpointer:\n",
            "  _component_: torchtune.training.Checkpointer\n",
            "  frequency: epoch\n",
            "  keep_last: 'true'\n",
            "  model_type: default\n",
            "  output_dir: finetune_results\n",
            "compile: 'false'\n",
            "dataset:\n",
            "  _component_: processed_dataset\n",
            "device: cuda\n",
            "dtype: bf16\n",
            "enable_activation_checkpointing: 'false'\n",
            "enable_activation_offloading: 'false'\n",
            "epochs: 1\n",
            "gradient_accumulation_steps: 1\n",
            "log_every_n_steps: 10\n",
            "log_peak_memory_stats: 'false'\n",
            "loss:\n",
            "  _component_: torchtune.modules.cross_entropy_loss\n",
            "  ignore_index: -100\n",
            "  reduction: mean\n",
            "max_steps_per_epoch: 'null'\n",
            "metric_logger:\n",
            "  _component_: torchtune.logging.ConsoleLogger\n",
            "model:\n",
            "  _component_: torchtune.models.llama3_2.llama3_2_3b\n",
            "optimizer:\n",
            "  _component_: bitsandbytes.optim.PagedAdamW8bit\n",
            "  lr: 3.0e-05\n",
            "optimizer_in_bwd: 'false'\n",
            "output_dir: finetune_results\n",
            "resume_from_checkpoint: ''\n",
            "seed: 42\n",
            "shuffle: 'true'\n",
            "tokenizer:\n",
            "  _component_: torchtune.text_tokenizers.llama_tokenizer\n",
            "  pretrained_tokenizer: /path/to/tokenizer\n",
            "  special_tokens: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tune cp full_finetune_single_device  full_finetune_single_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw9QrGCM1t4_",
        "outputId": "ba5a56c3-8f4a-4a8a-a31d-642caffe43e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied file to full_finetune_single_device.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tune run full_finetune_single_device --config custom_recipe.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFjrSCoTxyJo",
        "outputId": "2764ced0-7f4a-4c36-d617-290e2d824e21"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:torchtune.utils._logging:Running FullFinetuneRecipeSingleDevice with resolved config:\n",
            "\n",
            "batch_size: 8\n",
            "checkpointer:\n",
            "  _component_: torchtune.training.Checkpointer\n",
            "  frequency: epoch\n",
            "  keep_last: 'true'\n",
            "  model_type: default\n",
            "  output_dir: finetune_results\n",
            "compile: 'false'\n",
            "dataset:\n",
            "  _component_: processed_dataset\n",
            "device: cuda\n",
            "dtype: bf16\n",
            "enable_activation_checkpointing: 'false'\n",
            "enable_activation_offloading: 'false'\n",
            "epochs: 1\n",
            "gradient_accumulation_steps: 1\n",
            "log_every_n_steps: 10\n",
            "log_peak_memory_stats: 'false'\n",
            "loss:\n",
            "  _component_: torchtune.modules.cross_entropy_loss\n",
            "  ignore_index: -100\n",
            "  reduction: mean\n",
            "max_steps_per_epoch: 'null'\n",
            "metric_logger:\n",
            "  _component_: torchtune.logging.ConsoleLogger\n",
            "model:\n",
            "  _component_: torchtune.models.llama3_2.llama3_2_3b\n",
            "optimizer:\n",
            "  _component_: bitsandbytes.optim.PagedAdamW8bit\n",
            "  lr: 3.0e-05\n",
            "optimizer_in_bwd: 'false'\n",
            "output_dir: finetune_results\n",
            "resume_from_checkpoint: ''\n",
            "seed: 42\n",
            "shuffle: 'true'\n",
            "tokenizer:\n",
            "  _component_: torchtune.text_tokenizers.llama_tokenizer\n",
            "  pretrained_tokenizer: /path/to/tokenizer\n",
            "  special_tokens: []\n",
            "\n",
            "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 42. Local seed is seed + rank = 42 + 0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/config/_utils.py\", line 83, in _get_component_from_path\n",
            "    obj = getattr(obj, part)\n",
            "          ^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: module 'torchtune' has no attribute 'logging'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/config/_utils.py\", line 91, in _get_component_from_path\n",
            "    obj = import_module(mod)\n",
            "          ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1140, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'torchtune.logging'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tune\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/_cli/tune.py\", line 49, in main\n",
            "    parser.run(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/_cli/tune.py\", line 43, in run\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/_cli/run.py\", line 214, in _run_cmd\n",
            "    self._run_single_device(args, is_builtin=is_builtin)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/_cli/run.py\", line 108, in _run_single_device\n",
            "    runpy.run_path(str(args.recipe), run_name=\"__main__\")\n",
            "  File \"<frozen runpy>\", line 291, in run_path\n",
            "  File \"<frozen runpy>\", line 98, in _run_module_code\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/recipes/full_finetune_single_device.py\", line 803, in <module>\n",
            "    sys.exit(recipe_main())\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/config/_parse.py\", line 99, in wrapper\n",
            "    sys.exit(recipe_main(conf))\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/recipes/full_finetune_single_device.py\", line 797, in recipe_main\n",
            "    recipe.setup(cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/recipes/full_finetune_single_device.py\", line 253, in setup\n",
            "    self._metric_logger = config.instantiate(cfg.metric_logger)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/config/_instantiate.py\", line 112, in instantiate\n",
            "    return _instantiate_node(OmegaConf.to_object(config), *args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/config/_instantiate.py\", line 31, in _instantiate_node\n",
            "    _component_ = _get_component_from_path(node.get(\"_component_\"))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtune/config/_utils.py\", line 94, in _get_component_from_path\n",
            "    raise InstantiationError(\n",
            "torchtune.config._errors.InstantiationError: Error loading 'torchtune.logging.ConsoleLogger':\n",
            "ModuleNotFoundError(\"No module named 'torchtune.logging'\")\n",
            "Are you sure that 'logging' is importable from module 'torchtune'?\n"
          ]
        }
      ]
    }
  ]
}